{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Predicci\u00f3n de Supervivencia en el Titanic\n", "Este notebook sigue la metodolog\u00eda CRISP-DM para construir un modelo de Machine Learning que prediga la supervivencia \n", "de los pasajeros del Titanic. Est\u00e1 pensado como parte del Proyecto Final Integrador de la diplomatura. \n", "\n", "## Descripci\u00f3n General\n", "Se trabaja con el conjunto de datos p\u00fablico de Kaggle, \"Titanic: Machine Learning from Disaster\", y se generan nuevas caracter\u00edsticas \n", "a partir de los datos originales. Se eval\u00faan modelos de clasificaci\u00f3n, se comparan m\u00e9tricas (F1-score, precisi\u00f3n, recall, AUC), y se interpretan \n", "los resultados usando valores SHAP para identificar las variables m\u00e1s influyentes.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Comprensi\u00f3n del Negocio\n", "El objetivo es estimar la probabilidad de supervivencia de un pasajero en caso de un siniestro mar\u00edtimo. En un contexto de seguros,\n", "esto permitir\u00eda personalizar primas y coberturas seg\u00fan el riesgo de cada individuo.\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Importaci\u00f3n de librer\u00edas\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n", "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "import matplotlib.pyplot as plt\n", "\n", "# Configuraci\u00f3n de gr\u00e1ficos\n", "%matplotlib inline\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Carga de datos\n", "# Aseg\u00farate de que los archivos 'train.csv' y 'test.csv' de Kaggle est\u00e9n en la ruta especificada.\n", "train_path = 'data/train.csv'\n", "test_path = 'data/test.csv'\n", "train = pd.read_csv(train_path)\n", "test = pd.read_csv(test_path)\n", "train.head()\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Ingenier\u00eda de variables\n", "def add_features(df):\n", "    out = df.copy()\n", "    out['Title'] = out['Name'].str.extract(r',\\s*([^\\.]+)\\.').squeeze()\n", "    out['FamilySize'] = out['SibSp'] + out['Parch'] + 1\n", "    out['IsAlone'] = (out['FamilySize'] == 1).astype(int)\n", "    return out\n", "\n", "train = add_features(train)\n", "test  = add_features(test)\n", "\n", "# Imputaci\u00f3n de Age por mediana de Pclass y Sex\n", "age_medians = train.groupby(['Pclass','Sex'])['Age'].median()\n", "train['Age'] = train.apply(lambda r: age_medians.loc[r['Pclass'], r['Sex']] if pd.isna(r['Age']) else r['Age'], axis=1)\n", "test['Age']  = test.apply(lambda r: age_medians.loc[r['Pclass'], r['Sex']] if pd.isna(r['Age']) else r['Age'], axis=1)\n", "\n", "# Imputaci\u00f3n de Fare en test\n", "test['Fare'] = test['Fare'].fillna(train['Fare'].median())\n", "\n", "# Imputaci\u00f3n de Embarked\n", "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n", "test['Embarked']  = test['Embarked'].fillna(train['Embarked'].mode()[0])\n", "\n", "# Selecci\u00f3n de features\n", "target = 'Survived'\n", "features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','FamilySize','IsAlone','Title']\n", "X = train[features]\n", "y = train[target].astype(int)\n", "\n", "# Definici\u00f3n de columnas num\u00e9ricas y categ\u00f3ricas\n", "num_cols = ['Age','SibSp','Parch','Fare','FamilySize','IsAlone']\n", "cat_cols = [c for c in X.columns if c not in num_cols]\n", "\n", "# Preprocesador: escalado y codificaci\u00f3n\n", "preprocess = ColumnTransformer([\n", "    ('num', StandardScaler(with_mean=False), num_cols),\n", "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n", "])\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Modelado y evaluaci\u00f3n\n", "models = {\n", "    'logreg': LogisticRegression(max_iter=2000),\n", "    'rf': RandomForestClassifier(n_estimators=200, random_state=42)\n", "}\n", "\n", "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n", "scoring = {\n", "    'f1': 'f1',\n", "    'precision': 'precision',\n", "    'recall': 'recall',\n", "    'roc_auc': 'roc_auc'\n", "}\n", "\n", "X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n", "\n", "import numpy as np\n", "results = []\n", "trained = {}\n", "for name, clf in models.items():\n", "    pipe = Pipeline([('prep', preprocess), ('clf', clf)])\n", "    cv_results = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring)\n", "    pipe.fit(X_train, y_train)\n", "    trained[name] = pipe\n", "    # holdout\n", "    y_pred = pipe.predict(X_hold)\n", "    y_proba = pipe.predict_proba(X_hold)[:,1]\n", "    results.append({\n", "        'model': name,\n", "        'f1_cv_mean': np.mean(cv_results['test_f1']),\n", "        'precision_cv_mean': np.mean(cv_results['test_precision']),\n", "        'recall_cv_mean': np.mean(cv_results['test_recall']),\n", "        'roc_auc_cv_mean': np.mean(cv_results['test_roc_auc']),\n", "        'f1_holdout': f1_score(y_hold, y_pred),\n", "        'precision_holdout': precision_score(y_hold, y_pred),\n", "        'recall_holdout': recall_score(y_hold, y_pred),\n", "        'roc_auc_holdout': roc_auc_score(y_hold, y_proba)\n", "    })\n", "\n", "metrics_df = pd.DataFrame(results)\n", "# Mostrar m\u00e9tricas\n", "metrics_df\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Selecci\u00f3n del Modelo\n", "El modelo de Regresi\u00f3n Log\u00edstica obtuvo un desempe\u00f1o ligeramente superior en F1-score en comparaci\u00f3n con el Random Forest.\n", "Adem\u00e1s, su interpretabilidad facilita la explicaci\u00f3n de resultados a stakeholders no t\u00e9cnicos. Por ello, se selecciona \n", "la Regresi\u00f3n Log\u00edstica como modelo final para este proyecto.\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Interpretaci\u00f3n con valores SHAP\n", "# Usaremos una aproximaci\u00f3n lineal de SHAP para Regresi\u00f3n Log\u00edstica.\n", "best_model = 'logreg'\n", "pipe = trained[best_model]\n", "\n", "# Transformar los datos y obtener coeficientes\n", "X_trans = pipe.named_steps['prep'].transform(X)\n", "coef = pipe.named_steps['clf'].coef_[0]\n", "mean_trans = X_trans.mean(axis=0)\n", "\n", "# C\u00e1lculo de valores shap aproximados (escala de log-odds)\n", "shap_vals = (X_trans - mean_trans) * coef\n", "\n", "# Nombres de features transformadas\n", "num_cols = ['Age','SibSp','Parch','Fare','FamilySize','IsAlone']\n", "cat_cols = [c for c in features if c not in num_cols]\n", "cat_feature_names = pipe.named_steps['prep'].named_transformers_['cat'].get_feature_names_out(cat_cols)\n", "feature_names = np.concatenate([np.array(num_cols), cat_feature_names])\n", "\n", "# Mean absolute SHAP values\n", "mean_abs_shap = np.mean(np.abs(shap_vals), axis=0)\n", "\n", "# Gr\u00e1fico de barras\n", "import matplotlib.pyplot as plt\n", "n_top = 10\n", "sorted_idx = np.argsort(mean_abs_shap)[::-1][:n_top]\n", "plt.figure(figsize=(8,6))\n", "plt.barh(range(len(sorted_idx)), mean_abs_shap[sorted_idx][::-1])\n", "plt.yticks(range(len(sorted_idx)), feature_names[sorted_idx][::-1])\n", "plt.xlabel('Mean |SHAP value| (log-odds)')\n", "plt.title('Importancia de caracter\u00edsticas (SHAP aproximado)')\n", "plt.show()\n", "\n", "# Gr\u00e1fico beeswarm aproximado\n", "plt.figure(figsize=(8,6))\n", "for i, idx in enumerate(sorted_idx[::-1]):\n", "    vals = shap_vals[:, idx]\n", "    plt.scatter(vals, [i]*len(vals), c=vals, cmap='coolwarm', alpha=0.4, s=10)\n", "plt.yticks(range(len(sorted_idx)), feature_names[sorted_idx][::-1])\n", "plt.xlabel('SHAP value (log-odds)')\n", "plt.title('Distribuci\u00f3n de valores SHAP (aprox.)')\n", "plt.axvline(0, color='k', linewidth=0.5)\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Explicaci\u00f3n de los valores SHAP\n", "Los valores SHAP (Shapley Additive ExPlanations) descomponen la predicci\u00f3n de cada observaci\u00f3n en contribuciones \n", "de cada variable al resultado. Un valor SHAP positivo incrementa la probabilidad de supervivencia, mientras que uno \n", "negativo la disminuye. En el gr\u00e1fico de dispersi\u00f3n (beeswarm), cada punto representa una observaci\u00f3n. El color \n", "indica el valor original de la variable: rojo para valores altos y azul para valores bajos. Por ejemplo, en la \n", "variable `Age`, los puntos rojos corresponden a pasajeros de mayor edad (mayor impacto negativo en la supervivencia), \n", "mientras que los azules representan a pasajeros j\u00f3venes (impacto positivo). La posici\u00f3n horizontal del punto \n", "refleja la magnitud de la contribuci\u00f3n: valores a la derecha aumentan la supervivencia; a la izquierda, la reducen.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusiones\n", "El modelo de Regresi\u00f3n Log\u00edstica demostr\u00f3 un buen equilibrio entre desempe\u00f1o y interpretabilidad, con un F1-score de \n", "aproximadamente 0,78 en el conjunto de validaci\u00f3n. El an\u00e1lisis de SHAP evidenci\u00f3 que las variables m\u00e1s determinantes \n", "son la clase del pasajero, el g\u00e9nero, la edad y el t\u00edtulo. Esta informaci\u00f3n puede utilizarse para ajustar primas \n", "de seguros mar\u00edtimos y dise\u00f1ar pol\u00edticas diferenciadas. Para futuras mejoras se sugiere explorar modelos no lineales, \n", "incluir m\u00e9tricas de equidad y utilizar datos m\u00e1s recientes o variados para evitar sesgos hist\u00f3ricos.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 5}